# .github/workflows/pipeline.yml
name: Sticker Sales ML Pipeline

on:
  # Replaced schedule/workflow_dispatch with workflow_call to be executed by the orchestrator
  workflow_call:
    # Define outputs if you need to pass data to register_model.yml

jobs:
  etl_train:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.9"

      - name: Cache pip dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Check for data or code changes
        id: changes
        run: |
          echo "Checking for changes in data/raw/ or scripts/ since last run..."
          # Note: LAST_SUCCESS logic needs a way to track the last successful run's commit hash, 
          # which is complex with workflow_call. A simpler, more reliable way for 
          # an orchestrator-called pipeline is often to check changes against 'main' branch HEAD.
          # For now, we'll assume changes are always detected when called via orchestrator to simplify.
          # If you want to keep your specific git tag logic, it should still work.
          LAST_SUCCESS=$(git rev-list --tags --max-count=1)
          if [ -z "$LAST_SUCCESS" ]; then
            echo "::set-output name=changed::true"
            exit 0
          fi
          if git diff --quiet $LAST_SUCCESS HEAD -- data/raw scripts; then
            echo "No changes in data/raw or scripts. Skipping retrain."
            echo "::set-output name=changed::false"
          else
            echo "Changes detected. Proceeding with retrain."
            echo "::set-output name=changed::true"

      - name: Run ETL
        if: steps.changes.outputs.changed == 'true'
        run: python scripts/etl1.py
        working-directory: .

      - name: Train model
        if: steps.changes.outputs.changed == 'true'
        run: python scripts/train1.py
        working-directory: .
        
      # NOTE: Removed the 'Promote best model to Production in MLflow' step.
      # This task should now be handled exclusively by the next workflow: register_model.yml

      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: etl-logs
          path: logs/

      - name: Upload artifacts (model + metrics)
        uses: actions/upload-artifact@v4
        with:
          name: sticker-model-artifacts-${{ github.run_id }}
          path: artifacts/

      - name: Append metrics to summary
        if: always()
        run: |
          echo "## Model training metrics" >> $GITHUB_STEP_SUMMARY
          if [ -f artifacts/metrics.txt ]; then
            cat artifacts/metrics.txt >> $GITHUB_STEP_SUMMARY
          else
            echo "No metrics found" >> $GITHUB_STEP_SUMMARY
          fi
          